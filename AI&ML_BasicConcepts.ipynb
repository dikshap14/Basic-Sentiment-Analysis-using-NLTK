{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) Applied Statistics:\n",
    "(Make use of Pandas, Numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 1. For a given set of values in stats.xls that contains the list of employees, years\n",
    "of experience and their salary write a python script to calculate the mean, mode\n",
    "and median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emp#</th>\n",
       "      <th>YearsOfExp</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>126015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>100639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>125351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>25031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emp#  YearsOfExp  Salary\n",
       "0     1          10  126015\n",
       "1     2           1   12598\n",
       "2     3           8  100639\n",
       "3     4          10  125351\n",
       "4     5           2   25031"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(\"stats.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77821.2\n"
     ]
    }
   ],
   "source": [
    "mean=data['Salary'].mean()\n",
    "print(mean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100639\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mode=data['Salary'].mode()\n",
    "print(mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87654.0\n"
     ]
    }
   ],
   "source": [
    "median=data['Salary'].median()\n",
    "print(median) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ex2. For the above exercise determine the standard deviation and variance\n",
    "through python scripting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39847.6152810094\n"
     ]
    }
   ],
   "source": [
    "stdev=data['Salary'].std()\n",
    "print(stdev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587832443.5833337\n"
     ]
    }
   ],
   "source": [
    "variance=data['Salary'].var()\n",
    "print(variance) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) NLP (Make use of Pandas, NLTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 1. Write a python script that reads the data_in.csv from every cell in column\n",
    "labeled as comment and perform sentence tokenization and redirects in to\n",
    "column of data_out.csv. Perform the NE Chunking on these sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello there, how are you? Weather is awesome. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello Mr. Raja, how are you? Weather is awesom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello Mr. Raja, how are you. Weather is bad. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLP is great technique. It is nice to learn th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI is making difference in this world now.  It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  Hello there, how are you? Weather is awesome. ...\n",
       "1  Hello Mr. Raja, how are you? Weather is awesom...\n",
       "2  Hello Mr. Raja, how are you. Weather is bad. I...\n",
       "3  NLP is great technique. It is nice to learn th...\n",
       "4  AI is making difference in this world now.  It..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataIn=pd.read_csv('data_in.csv')\n",
    "dataIn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Hello there, how are you? Weather is awesome. ...\n",
      "1    Hello Mr. Raja, how are you? Weather is awesom...\n",
      "2    Hello Mr. Raja, how are you. Weather is bad. I...\n",
      "3    NLP is great technique. It is nice to learn th...\n",
      "4    AI is making difference in this world now.  It...\n",
      "Name: Comment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataIn['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hello there, how are you? Weather is awesome. Its raining here now.']\n",
      " ['Hello Mr. Raja, how are you? Weather is awesome. Its raining here now.']\n",
      " ['Hello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.']\n",
      " ['NLP is great technique. It is nice to learn this technique.']\n",
      " ['AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.']]\n"
     ]
    }
   ],
   "source": [
    "dataInValues=dataIn.values\n",
    "print(dataInValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NE Chunking\n",
    "\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello there, how are you?', 'Weather is awesome.', 'Its raining here now.']\n",
      "['Hello Mr. Raja, how are you?', 'Weather is awesome.', 'Its raining here now.']\n",
      "['Hello Mr. Raja, how are you.', 'Weather is bad.', 'Its heavily raining here now.']\n",
      "['NLP is great technique.', 'It is nice to learn this technique.']\n",
      "['AI is making difference in this world now.', 'It would be helpful for betterment of human life.', 'We need to make advantage of that.']\n"
     ]
    }
   ],
   "source": [
    "#print(dataInValues.size)\n",
    "#print(dataInValues.item(dataInValues.size-1))\n",
    "i=0\n",
    "while(i<=dataInValues.size-1):\n",
    "    #print(dataInValues.item(i))\n",
    "    sentence = sent_tokenize(dataInValues.item(i))\n",
    "    print(sentence)\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply for loop till the size of dataframe\n",
    "#dataInValues.item(1)\n",
    "#sentence = sent_tokenize(dataInValues.item(1))\n",
    "#(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Hello there, how are you?\n",
      "  Weather is awesome.\n",
      "  Its raining here now.)\n",
      "(S\n",
      "  Hello Mr. Raja, how are you?\n",
      "  Weather is awesome.\n",
      "  Its raining here now.)\n",
      "(S\n",
      "  Hello Mr. Raja, how are you.\n",
      "  Weather is bad.\n",
      "  Its heavily raining here now.)\n",
      "(S NLP is great technique. It is nice to learn this technique.)\n",
      "(S\n",
      "  AI is making difference in this world now.\n",
      "  It would be helpful for betterment of human life.\n",
      "  We need to make advantage of that.)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while(i<=dataInValues.size-1):\n",
    "    #print(dataInValues.item(i))\n",
    "    chunksentence=ne_chunk(sent_tokenize(dataInValues.item(i)))\n",
    "    print(chunksentence)\n",
    "    i=i+1\n",
    "#chunksentence=ne_chunk(sent_tokenize(dataInValues.item(1)))\n",
    "#print(chunksentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunksentence.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 2. Write a python script that reads the data_in.csv from every cell in column\n",
    "labeled as comment and perform word tokenization and redirects in to column of\n",
    "data_out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.']\n",
      "['Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.']\n",
      "['Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.']\n",
      "['Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.']\n",
      "['Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "i=0\n",
    "while(i<=dataInValues.size-1):\n",
    "    #print(dataInValues.item(i))\n",
    "    word= word_tokenize(dataInValues.item(1))\n",
    "    print(word)\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex3. From an input file data.txt it is required to identify the POS-Tagging and\n",
    "display it on tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hello there</th>\n",
       "      <th>how are you? Weather is awesome. Its raining here now.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello Mr. Raja</td>\n",
       "      <td>how are you? Weather is awesome. Its raining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello Mr. Raja</td>\n",
       "      <td>how are you. Weather is bad. Its heavily rain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP is great technique. It is nice to learn th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI is making difference in this world now.  It...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Hello there  \\\n",
       "0                                     Hello Mr. Raja   \n",
       "1                                     Hello Mr. Raja   \n",
       "2  NLP is great technique. It is nice to learn th...   \n",
       "3  AI is making difference in this world now.  It...   \n",
       "\n",
       "   how are you? Weather is awesome. Its raining here now.  \n",
       "0   how are you? Weather is awesome. Its raining ...       \n",
       "1   how are you. Weather is bad. Its heavily rain...       \n",
       "2                                                NaN       \n",
       "3                                                NaN       "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPOS=pd.read_csv('data.txt')\n",
    "dataPOS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hello Mr. Raja'\n",
      "  ' how are you? Weather is awesome. Its raining here now.']\n",
      " ['Hello Mr. Raja'\n",
      "  ' how are you. Weather is bad. Its heavily raining here now.']\n",
      " ['NLP is great technique. It is nice to learn this technique.' nan]\n",
      " ['AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.'\n",
      "  nan]]\n"
     ]
    }
   ],
   "source": [
    "dataPOSvalues=dataPOS.values\n",
    "print(dataPOSvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr', 'Raja']\n",
      "POS Tagging: \n",
      "[('Hello', 'NNP'), ('Mr', 'NNP'), ('Raja', 'NNP')]\n",
      "['how', 'are', 'you', 'Weather', 'is', 'awesome', 'Its', 'raining', 'here', 'now']\n",
      "POS Tagging: \n",
      "[('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('Weather', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ'), ('Its', 'PRP$'), ('raining', 'VBG'), ('here', 'RB'), ('now', 'RB')]\n",
      "['Hello', 'Mr', 'Raja']\n",
      "POS Tagging: \n",
      "[('Hello', 'NNP'), ('Mr', 'NNP'), ('Raja', 'NNP')]\n",
      "['how', 'are', 'you', 'Weather', 'is', 'bad', 'Its', 'heavily', 'raining', 'here', 'now']\n",
      "POS Tagging: \n",
      "[('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('Weather', 'NNP'), ('is', 'VBZ'), ('bad', 'JJ'), ('Its', 'PRP$'), ('heavily', 'RB'), ('raining', 'VBG'), ('here', 'RB'), ('now', 'RB')]\n",
      "['NLP', 'is', 'great', 'technique', 'It', 'is', 'nice', 'to', 'learn', 'this', 'technique']\n",
      "POS Tagging: \n",
      "[('NLP', 'NNP'), ('is', 'VBZ'), ('great', 'JJ'), ('technique', 'NN'), ('It', 'PRP'), ('is', 'VBZ'), ('nice', 'JJ'), ('to', 'TO'), ('learn', 'VB'), ('this', 'DT'), ('technique', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "#Apply for loop till the size of dataframe\n",
    "#wordforPOS= word_tokenize(dataPOSvalues.item(1))\n",
    "\n",
    "i=0\n",
    "while(i<=dataInValues.size-1):\n",
    "    #print(dataInValues.item(i))\n",
    "    tokenizer=nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    wordforPOS=tokenizer.tokenize(dataPOSvalues.item(i))\n",
    "    print(wordforPOS)\n",
    "    print(\"POS Tagging: \" )\n",
    "    from nltk.tag import pos_tag\n",
    "    poswords=pos_tag(wordforPOS)\n",
    "    print(poswords)\n",
    "    i=i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS Mapping\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#from nltk.tag import pos_tag\n",
    "#poswords=pos_tag(wordforPOS)\n",
    "#print(poswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poswords.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 4. For a given text file exclude the stop words and perform the Stemming &\n",
    "lemmatization and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEMMING  hello\n",
      "LEMMATIZATION  Hello\n",
      "STEMMING  mr\n",
      "LEMMATIZATION  Mr\n",
      "STEMMING  raja\n",
      "LEMMATIZATION  Raja\n",
      "STEMMING  how\n",
      "LEMMATIZATION  how\n",
      "STEMMING  are\n",
      "LEMMATIZATION  are\n",
      "STEMMING  you\n",
      "LEMMATIZATION  you\n",
      "STEMMING  weather\n",
      "LEMMATIZATION  Weather\n",
      "STEMMING  is\n",
      "LEMMATIZATION  is\n",
      "STEMMING  awesom\n",
      "LEMMATIZATION  awesome\n",
      "STEMMING  it\n",
      "LEMMATIZATION  Its\n",
      "STEMMING  rain\n",
      "LEMMATIZATION  raining\n",
      "STEMMING  here\n",
      "LEMMATIZATION  here\n",
      "STEMMING  now\n",
      "LEMMATIZATION  now\n",
      "STEMMING  hello\n",
      "LEMMATIZATION  Hello\n",
      "STEMMING  mr\n",
      "LEMMATIZATION  Mr\n",
      "STEMMING  raja\n",
      "LEMMATIZATION  Raja\n",
      "STEMMING  how\n",
      "LEMMATIZATION  how\n",
      "STEMMING  are\n",
      "LEMMATIZATION  are\n",
      "STEMMING  you\n",
      "LEMMATIZATION  you\n",
      "STEMMING  weather\n",
      "LEMMATIZATION  Weather\n",
      "STEMMING  is\n",
      "LEMMATIZATION  is\n",
      "STEMMING  bad\n",
      "LEMMATIZATION  bad\n",
      "STEMMING  it\n",
      "LEMMATIZATION  Its\n",
      "STEMMING  heavili\n",
      "LEMMATIZATION  heavily\n",
      "STEMMING  rain\n",
      "LEMMATIZATION  raining\n",
      "STEMMING  here\n",
      "LEMMATIZATION  here\n",
      "STEMMING  now\n",
      "LEMMATIZATION  now\n",
      "STEMMING  nlp\n",
      "LEMMATIZATION  NLP\n",
      "STEMMING  is\n",
      "LEMMATIZATION  is\n",
      "STEMMING  great\n",
      "LEMMATIZATION  great\n",
      "STEMMING  techniqu\n",
      "LEMMATIZATION  technique\n",
      "STEMMING  it\n",
      "LEMMATIZATION  It\n",
      "STEMMING  is\n",
      "LEMMATIZATION  is\n",
      "STEMMING  nice\n",
      "LEMMATIZATION  nice\n",
      "STEMMING  to\n",
      "LEMMATIZATION  to\n",
      "STEMMING  learn\n",
      "LEMMATIZATION  learn\n",
      "STEMMING  this\n",
      "LEMMATIZATION  this\n",
      "STEMMING  techniqu\n",
      "LEMMATIZATION  technique\n"
     ]
    }
   ],
   "source": [
    "#STEMMING and LEMMATIZATION\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import stem\n",
    "\n",
    "i=0\n",
    "while(i<=dataInValues.size-1):\n",
    "    #print(dataInValues.item(i))\n",
    "    tokenizer=nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    wordforPOS=tokenizer.tokenize(dataPOSvalues.item(i))\n",
    "    \n",
    "    ps=SnowballStemmer('english')\n",
    "    list_words=wordforPOS\n",
    "    wn_lemat=stem.WordNetLemmatizer()\n",
    "\n",
    "    #print(list_words)\n",
    "    for word in list_words:\n",
    "        print(\"STEMMING  \"+ ps.stem(word))\n",
    "        print(\"LEMMATIZATION  \" +wn_lemat.lemmatize(word))\n",
    "    \n",
    "    i=i+1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 5. Create a small dictionary file with required set of words with weightage\n",
    "attached to it with positive and negative numbers. Create a python script that\n",
    "analyzes the given text file and classify it as negative or positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for line in open('senti_analyze.txt'):\n",
    "    word,score=line.split('\\t')\n",
    "    senti_dict[word]=int(score)\n",
    "\n",
    "print(sum(senti_dict.get(word,0)for word in words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
