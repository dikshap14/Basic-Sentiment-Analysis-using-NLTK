{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) Applied Statistics:\n",
    "(Make use of Pandas, Numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 1. For a given set of values in stats.xls that contains the list of employees, years\n",
    "of experience and their salary write a python script to calculate the mean, mode\n",
    "and median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emp#</th>\n",
       "      <th>YearsOfExp</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>126015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>100639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>125351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>25031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emp#  YearsOfExp  Salary\n",
       "0     1          10  126015\n",
       "1     2           1   12598\n",
       "2     3           8  100639\n",
       "3     4          10  125351\n",
       "4     5           2   25031"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(\"stats.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77821.2\n"
     ]
    }
   ],
   "source": [
    "mean=data['Salary'].mean()\n",
    "print(mean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100639\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mode=data['Salary'].mode()\n",
    "print(mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87654.0\n"
     ]
    }
   ],
   "source": [
    "median=data['Salary'].median()\n",
    "print(median) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ex2. For the above exercise determine the standard deviation and variance\n",
    "through python scripting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39847.6152810094\n"
     ]
    }
   ],
   "source": [
    "stdev=data['Salary'].std()\n",
    "print(stdev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587832443.5833337\n"
     ]
    }
   ],
   "source": [
    "variance=data['Salary'].var()\n",
    "print(variance) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) NLP (Make use of Pandas, NLTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 1. Write a python script that reads the data_in.csv from every cell in column\n",
    "labeled as comment and perform sentence tokenization and redirects in to\n",
    "column of data_out.csv. Perform the NE Chunking on these sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello there, how are you? Weather is awesome. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello Mr. Raja, how are you? Weather is awesom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello Mr. Raja, how are you. Weather is bad. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLP is great technique. It is nice to learn th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI is making difference in this world now.  It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  Hello there, how are you? Weather is awesome. ...\n",
       "1  Hello Mr. Raja, how are you? Weather is awesom...\n",
       "2  Hello Mr. Raja, how are you. Weather is bad. I...\n",
       "3  NLP is great technique. It is nice to learn th...\n",
       "4  AI is making difference in this world now.  It..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataIn=pd.read_csv('data_in.csv')\n",
    "dataIn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Hello there, how are you? Weather is awesome. ...\n",
      "1    Hello Mr. Raja, how are you? Weather is awesom...\n",
      "2    Hello Mr. Raja, how are you. Weather is bad. I...\n",
      "3    NLP is great technique. It is nice to learn th...\n",
      "4    AI is making difference in this world now.  It...\n",
      "Name: Comment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataIn['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hello there, how are you? Weather is awesome. Its raining here now.']\n",
      " ['Hello Mr. Raja, how are you? Weather is awesome. Its raining here now.']\n",
      " ['Hello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.']\n",
      " ['NLP is great technique. It is nice to learn this technique.']\n",
      " ['AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.']]\n"
     ]
    }
   ],
   "source": [
    "dataInValues=dataIn.values\n",
    "print(dataInValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NE Chunking\n",
    "\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Raja, how are you?', 'Weather is awesome.', 'Its raining here now.']\n"
     ]
    }
   ],
   "source": [
    "#Apply for loop till the size of dataframe\n",
    "dataInValues.item(1)\n",
    "sentence = sent_tokenize(dataInValues.item(1))\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Hello Mr. Raja, how are you?\n",
      "  Weather is awesome.\n",
      "  Its raining here now.)\n"
     ]
    }
   ],
   "source": [
    "chunksentence=ne_chunk(sent_tokenize(dataInValues.item(1)))\n",
    "print(chunksentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunksentence.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 2. Write a python script that reads the data_in.csv from every cell in column\n",
    "labeled as comment and perform word tokenization and redirects in to column of\n",
    "data_out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word= word_tokenize(dataInValues.item(1))\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex3. From an input file data.txt it is required to identify the POS-Tagging and\n",
    "display it on tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hello there</th>\n",
       "      <th>how are you? Weather is awesome. Its raining here now.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello Mr. Raja</td>\n",
       "      <td>how are you? Weather is awesome. Its raining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello Mr. Raja</td>\n",
       "      <td>how are you. Weather is bad. Its heavily rain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP is great technique. It is nice to learn th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI is making difference in this world now.  It...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Hello there  \\\n",
       "0                                     Hello Mr. Raja   \n",
       "1                                     Hello Mr. Raja   \n",
       "2  NLP is great technique. It is nice to learn th...   \n",
       "3  AI is making difference in this world now.  It...   \n",
       "\n",
       "   how are you? Weather is awesome. Its raining here now.  \n",
       "0   how are you? Weather is awesome. Its raining ...       \n",
       "1   how are you. Weather is bad. Its heavily rain...       \n",
       "2                                                NaN       \n",
       "3                                                NaN       "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPOS=pd.read_csv('data.txt')\n",
    "dataPOS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hello Mr. Raja'\n",
      "  ' how are you? Weather is awesome. Its raining here now.']\n",
      " ['Hello Mr. Raja'\n",
      "  ' how are you. Weather is bad. Its heavily raining here now.']\n",
      " ['NLP is great technique. It is nice to learn this technique.' nan]\n",
      " ['AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.'\n",
      "  nan]]\n"
     ]
    }
   ],
   "source": [
    "dataPOSvalues=dataPOS.values\n",
    "print(dataPOSvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'are', 'you', 'Weather', 'is', 'awesome', 'Its', 'raining', 'here', 'now']\n"
     ]
    }
   ],
   "source": [
    "#Apply for loop till the size of dataframe\n",
    "#wordforPOS= word_tokenize(dataPOSvalues.item(1))\n",
    "\n",
    "\n",
    "tokenizer=nltk.RegexpTokenizer(r\"\\w+\")\n",
    "wordforPOS=tokenizer.tokenize(dataPOSvalues.item(1))\n",
    "print(wordforPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS Mapping\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "poswords=pos_tag(wordforPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('Weather', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ'), ('Its', 'PRP$'), ('raining', 'VBG'), ('here', 'RB'), ('now', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "print(poswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import Tree\n",
    "Tree(poswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 4. For a given text file exclude the stop words and perform the Stemming &\n",
    "lemmatization and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEMMING  how\n",
      "LEMMATIZATION  how\n",
      "STEMMING  are\n",
      "LEMMATIZATION  are\n",
      "STEMMING  you\n",
      "LEMMATIZATION  you\n",
      "STEMMING  weather\n",
      "LEMMATIZATION  Weather\n",
      "STEMMING  is\n",
      "LEMMATIZATION  is\n",
      "STEMMING  awesom\n",
      "LEMMATIZATION  awesome\n",
      "STEMMING  it\n",
      "LEMMATIZATION  Its\n",
      "STEMMING  rain\n",
      "LEMMATIZATION  raining\n",
      "STEMMING  here\n",
      "LEMMATIZATION  here\n",
      "STEMMING  now\n",
      "LEMMATIZATION  now\n"
     ]
    }
   ],
   "source": [
    "#STEMMING and LEMMATIZATION\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import stem\n",
    "ps=SnowballStemmer('english')\n",
    "list_words=wordforPOS\n",
    "wn_lemat=stem.WordNetLemmatizer()\n",
    "\n",
    "#print(list_words)\n",
    "for word in list_words:\n",
    "    print(\"STEMMING  \"+ ps.stem(word))\n",
    "    print(\"LEMMATIZATION  \" +wn_lemat.lemmatize(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 5. Create a small dictionary file with required set of words with weightage\n",
    "attached to it with positive and negative numbers. Create a python script that\n",
    "analyzes the given text file and classify it as negative or positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) Machine Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Machine Learning Linear regression assignments\n",
    "Write a python script\n",
    "BEST FIT LINE - Calling SKlearn linear regression\n",
    "Ex 1. Data:\n",
    "1. Download the MPG data file from UCI Machine Learning\n",
    "repository https://archive.ics.uci.edu/ml/machine-learningdatabases/\n",
    "auto-mpg/\n",
    "2. Identify target variable and independent variable.\n",
    "3. Prepare the data file\n",
    "Univariate Regression\n",
    "Ex 2. Import relevant python libraries and sklearn linear_model\n",
    "Ex 3. Split the file into train [80%] and test [20%] data\n",
    "Ex 4. Apply linear regression\n",
    "Ex 5. Train the model using the training sets\n",
    "Ex 6. Display the coefficients coef, intercept and residues\n",
    "Ex 7.Predict using test data\n",
    "Ex 8. Perform Accuracy check using the R Square\n",
    "Ex 9. Display using scatter plot the data points and the best fit line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-variate Regression\n",
    "Repeat the above steps\n",
    "BEST FIT LINE - Cost function using un-constrained method - Gradient descent\n",
    "Ex 1. Use the downloaded data\n",
    "Ex 2. Convert this data to array\n",
    "Ex 3. Define the learning rate and no. of iterations as 0.0001 and 1000\n",
    "respectively along with y-intercept and slope\n",
    "Ex 4. Create the functions to get the BEST FIT line\n",
    "1. Compute error for the line given the points\n",
    "2. Step gradient function\n",
    "3. Gradient descent\n",
    "Ex 5. Display using scatter plot the data points and the best fit line\n",
    "Ex 6. Display the Gradient and y-intercept value in the form y = mx+c\n",
    "Ex 7. Find the BEST FIT line i.e., m and c of y=mx+c with least error using trial and\n",
    "error method i.e., modify learning rate or iterations or both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning KNN assignments\n",
    "Ex 1. Data:\n",
    "1. Download the census data file from UCI Machine Learning\n",
    "repository http://archive.ics.uci.edu/ml/machine-learningdatabases/\n",
    "haberman/\n",
    "2. Identify target variable and independent variable.\n",
    "3. Prepare the data file\n",
    "Ex 2. Import relevant python libraries and sklearn KNN model\n",
    "Ex 3. Split the file into train [80%] and test [20%] data\n",
    "Ex 4. Apply KNN algorithm\n",
    "Ex 5. Train the model using the training set\n",
    "Ex 6. Predict using test data\n",
    "Ex 8. Perform Accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
